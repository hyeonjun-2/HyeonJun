{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_pXDEusQ_ZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db030546-9d73-423a-8b6d-c57804e148cb"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 26.2 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 28.4 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███                             | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████                            | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████                         | 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 276 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 296 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 307 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 327 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 348 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 368 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 389 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 399 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 409 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 419 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 440 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 450 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 460 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 471 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 481 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 501 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 512 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 522 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 532 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 542 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 552 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 563 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 573 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 583 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 593 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 614 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 624 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 634 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 645 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 655 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 665 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 675 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 686 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 696 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 706 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 727 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 737 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 747 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 757 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 768 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 778 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 788 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 798 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 808 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 819 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 829 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 839 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 849 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 860 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 870 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 880 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 890 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 901 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 911 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 921 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 931 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 942 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 952 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 962 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 972 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 983 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 993 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2 MB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWASjtg1Q1Za"
      },
      "source": [
        "import sentencepiece as spm\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "import csv"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5cUWdxLQ79B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4896796-196b-488b-974f-64ed604464c6"
      },
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"ratings.txt\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ratings.txt', <http.client.HTTPMessage at 0x7fd58e3e1310>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uzXP1V_XRWuc",
        "outputId": "ba157186-47b8-412a-c21e-3f6e171e70fa"
      },
      "source": [
        "naver_df = pd.read_table('ratings.txt')\n",
        "naver_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8112052</td>\n",
              "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8132799</td>\n",
              "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4655635</td>\n",
              "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9251303</td>\n",
              "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10067386</td>\n",
              "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                           document  label\n",
              "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
              "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
              "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
              "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
              "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlLVUK2iRXs9",
        "outputId": "5dd80737-8016-48e8-ad48-77d2dce44b3c"
      },
      "source": [
        "#리뷰 갯수 출력\n",
        "print(\"리뷰 개수 : \",len(naver_df))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "리뷰 개수 :  200000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUPdSsHhRZsB",
        "outputId": "e4a49882-41e7-4bb5-9ced-74497e354483"
      },
      "source": [
        "# NuLL확인\n",
        "naver_df.isnull().values.any()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNVdxX_dRbBB",
        "outputId": "6b083216-b22a-4599-bd0b-3aa5d3fa3469"
      },
      "source": [
        "# NULL 행 제거 \n",
        "naver_df = naver_df.dropna(how = 'any')\n",
        "#NULL존재 확인\n",
        "naver_df.isnull().values.any()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvtNIulORd_v",
        "outputId": "2747e796-4ea0-4a37-d969-df6c52412972"
      },
      "source": [
        "#리뷰 갯수 출력하기\n",
        "print(\"리뷰 개수 : \",len(naver_df))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "리뷰 개수 :  199992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDzx8wWLRfQy"
      },
      "source": [
        "with open('naver_review.txt', 'w', encoding='utf8') as f:\n",
        "    f.write('\\n'.join(naver_df['document']))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-Gtz5cuSAkG"
      },
      "source": [
        "corpus = 'naver_review.txt'\n",
        "prefix = 'naver'\n",
        "vocab_size = 5000\n",
        "\n",
        "spm.SentencePieceTrainer.Train(f'--input={corpus} --model_prefix={prefix} --vocab_size={vocab_size}' +\n",
        "                               ' --model_type=bpe' + \n",
        "                               ' --max_sentence_length=9999')\n",
        "                               "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Bf6ljP7WSjf0",
        "outputId": "2c16f25b-10fe-4c3e-ce24-18e5b374cce8"
      },
      "source": [
        "# vocab불러오기 pd.read_csv\n",
        "vocab_list = pd.read_csv('naver.vocab', sep = '\\t', header=None, quoting=csv.QUOTE_NONE)\n",
        "# vocab 10개출력\n",
        "vocab_list.sample(10)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4257</th>\n",
              "      <td>ᅩ</td>\n",
              "      <td>-4254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4279</th>\n",
              "      <td>젼</td>\n",
              "      <td>-4276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>▁또</td>\n",
              "      <td>-254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1476</th>\n",
              "      <td>▁자기</td>\n",
              "      <td>-1473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1147</th>\n",
              "      <td>▁영화중</td>\n",
              "      <td>-1144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>▁유</td>\n",
              "      <td>-95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3849</th>\n",
              "      <td>숨</td>\n",
              "      <td>-3846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2171</th>\n",
              "      <td>▁류</td>\n",
              "      <td>-2168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>이게</td>\n",
              "      <td>-1494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>959</th>\n",
              "      <td>▁OOO</td>\n",
              "      <td>-956</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0     1\n",
              "4257     ᅩ -4254\n",
              "4279     젼 -4276\n",
              "257     ▁또  -254\n",
              "1476   ▁자기 -1473\n",
              "1147  ▁영화중 -1144\n",
              "98      ▁유   -95\n",
              "3849     숨 -3846\n",
              "2171    ▁류 -2168\n",
              "1497    이게 -1494\n",
              "959   ▁OOO  -956"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jPxW9EiS1m4",
        "outputId": "e768ef24-9d47-46e2-97ee-4973fd52390b"
      },
      "source": [
        "# vocab_file load하기\n",
        "sp = spm.SentencePieceProcessor()\n",
        "vocab_file = 'naver.model'\n",
        "sp.load(vocab_file)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJhhBfpaS3kI",
        "outputId": "fc0ef100-2b71-4ecb-fbf2-a0629a516f88"
      },
      "source": [
        "lines = [\n",
        "  \"뭐 이딴 것도 영화냐.\",\n",
        "  \"진짜 최고의 영화입니다 ㅋㅋ\",\n",
        "]\n",
        "for line in lines:\n",
        "  print(line)\n",
        "  print(sp.encode_as_pieces(line))\n",
        "  print(sp.encode_as_ids(line))\n",
        "  print()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "뭐 이딴 것도 영화냐.\n",
            "['▁뭐', '▁이딴', '▁것도', '▁영화냐', '.']\n",
            "[132, 966, 1296, 2590, 3276]\n",
            "\n",
            "진짜 최고의 영화입니다 ㅋㅋ\n",
            "['▁진짜', '▁최고의', '▁영화입니다', '▁ᄏᄏ']\n",
            "[54, 200, 821, 85]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYy9_TZJS4Nm",
        "outputId": "3fe1a0b7-371c-4454-db23-b28320873d10"
      },
      "source": [
        "sp.GetPieceSize()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xtvIznhAS5hz",
        "outputId": "ab7d1aad-7f22-450a-fb17-83596377834b"
      },
      "source": [
        "sp.IdToPiece(123)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'▁배우'"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTQfvsMAS7V1",
        "outputId": "c18eec0c-a447-472e-fe93-2a5302b1865d"
      },
      "source": [
        "sp.PieceToId('▁배우') "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "123"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "g6xVyFbtS829",
        "outputId": "35947887-48a3-48c8-c051-0cac55a4de42"
      },
      "source": [
        "sp.DecodeIds(sp.encode_as_ids(lines[0]))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'뭐 이딴 것도 영화냐.'"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2-xspH72S-Km",
        "outputId": "e312db09-5acf-4404-8a74-566b590444b0"
      },
      "source": [
        "sp.DecodePieces(sp.encode_as_pieces(lines[0])) # 서브워드 시퀀스 입력"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'뭐 이딴 것도 영화냐.'"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Gumcqt0S_NY",
        "outputId": "a4d09247-a312-4c06-d29a-bfa8a361580f"
      },
      "source": [
        "print(sp.encode('진짜 최고의 영화입니다 ㅋㅋ', out_type=str))\n",
        "print(sp.encode('진짜 최고의 영화입니다 ㅋㅋ', out_type=int))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['▁진짜', '▁최고의', '▁영화입니다', '▁ᄏᄏ']\n",
            "[54, 200, 821, 85]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MIcSiOvYRv_"
      },
      "source": [
        "# word Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8T-UD-zdEmy"
      },
      "source": [
        "## One-Hot Encoding 실습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlJb9WMxYTmh"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "#입력문장\n",
        "raw_inputs = [\n",
        "             '나는 학생입니다.',\n",
        "             '나는 좋은 선생님 입니다.',\n",
        "             '당신은 매우 좋은 선생님 입니다.'\n",
        "]\n",
        "\n",
        "raw_labels = [1,0,0] # 학생이 존재하면 1 없으면 0"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKDSZJexdbOW",
        "outputId": "7bf69f5c-57e1-490d-949f-bebc717d826b"
      },
      "source": [
        "#문장을 띄어쓰기 단위로 분할\n",
        "\n",
        "words = []\n",
        "for s in raw_inputs:\n",
        "  words.extend(s.split(' '))\n",
        "\n",
        "#중복단어 제거\n",
        "words = list(dict.fromkeys(words))\n",
        "\n",
        "word_to_idx = {\n",
        "    \"[PAD]\" : 0,\n",
        "    \"[UNK]\" : 1,\n",
        "}\n",
        "\n",
        "for w in words:\n",
        "  word_to_idx[w] = len(word_to_idx)\n",
        "\n",
        "idx_to_word = {i : w for w, i in word_to_idx.items()}\n",
        "\n",
        "print(idx_to_word)\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: '[PAD]', 1: '[UNK]', 2: '나는', 3: '학생입니다.', 4: '좋은', 5: '선생님', 6: '입니다.', 7: '당신은', 8: '매우'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFq5g_HUgAwl",
        "outputId": "49d19135-f541-4f78-916b-3837d88020a0"
      },
      "source": [
        "word_to_idx"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'[PAD]': 0,\n",
              " '[UNK]': 1,\n",
              " '나는': 2,\n",
              " '당신은': 7,\n",
              " '매우': 8,\n",
              " '선생님': 5,\n",
              " '입니다.': 6,\n",
              " '좋은': 4,\n",
              " '학생입니다.': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9O8CNJpeEEm",
        "outputId": "e923108c-90f1-4450-850d-3ee562500c15"
      },
      "source": [
        "train_inputs = []\n",
        "for s in raw_inputs:\n",
        "  row = [word_to_idx[w] for w in s.split()]\n",
        "  row += [0] * (5 - len(row))\n",
        "  train_inputs .append(row)\n",
        "\n",
        "train_inputs = np.array(train_inputs)\n",
        "\n",
        "print(train_inputs)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2 3 0 0 0]\n",
            " [2 4 5 6 0]\n",
            " [7 8 4 5 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5cIC4d8fDIr",
        "outputId": "300f3e47-9754-47cf-c209-868abd5490f7"
      },
      "source": [
        "# one -hot metrix 생성\n",
        "onehot_metrix = np.eye(len(word_to_idx))\n",
        "print(onehot_metrix)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18MuNRvXelI4",
        "outputId": "b50eb567-5244-486e-b3c0-10e4aef4c44a"
      },
      "source": [
        "train_onehots=  onehot_metrix[train_inputs]\n",
        "print(train_onehots) # 메모리 낭비가 심하다."
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "  [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 1. 0. 0.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfmByA1KfQHY",
        "outputId": "bf8bcae1-6580-439a-ef09-28a08bfb1dd2"
      },
      "source": [
        "print(np.argmax(train_onehots, axis = -1))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2 3 0 0 0]\n",
            " [2 4 5 6 0]\n",
            " [7 8 4 5 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RzkUgLpfYWO"
      },
      "source": [
        "x = np.argmax(train_onehots, axis = -1)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJauTS2XfgR8"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as L"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41HkrpAGfk5k",
        "outputId": "e907166a-d33f-475f-f038-bbc330a69f90"
      },
      "source": [
        "x_len = train_onehots.shape\n",
        "inp = tf.convert_to_tensor(x, dtype = tf.int32)\n",
        "inp_len = tf.convert_to_tensor(x_len, dtype = tf.int32)\n",
        "\n",
        "print(inp)\n",
        "print(inp_len)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[2 3 0 0 0]\n",
            " [2 4 5 6 0]\n",
            " [7 8 4 5 6]], shape=(3, 5), dtype=int32)\n",
            "tf.Tensor([3 5 9], shape=(3,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMeMr7nbf5Hd"
      },
      "source": [
        "vocab = 1000\n",
        "dim = 3\n",
        "embed = L.Embedding(vocab, dim)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPcX0Z-9gSlX",
        "outputId": "f355be0e-f986-4f6d-e38b-8292ad5358a1"
      },
      "source": [
        "embed(inp)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 5, 3), dtype=float32, numpy=\n",
              "array([[[ 1.9377578e-02,  4.4603262e-02, -3.3578716e-02],\n",
              "        [ 7.4099749e-05,  3.5429273e-02, -3.7045367e-03],\n",
              "        [-2.1648562e-02, -4.7007062e-02, -3.0328631e-03],\n",
              "        [-2.1648562e-02, -4.7007062e-02, -3.0328631e-03],\n",
              "        [-2.1648562e-02, -4.7007062e-02, -3.0328631e-03]],\n",
              "\n",
              "       [[ 1.9377578e-02,  4.4603262e-02, -3.3578716e-02],\n",
              "        [ 7.7015534e-03,  1.4470223e-02,  2.0395145e-03],\n",
              "        [ 4.9058344e-02,  2.1654677e-02, -8.7254122e-04],\n",
              "        [-3.8616288e-02, -8.9075677e-03, -4.4052314e-02],\n",
              "        [-2.1648562e-02, -4.7007062e-02, -3.0328631e-03]],\n",
              "\n",
              "       [[-3.1596266e-02,  2.2611666e-02, -1.6120147e-02],\n",
              "        [ 3.8933549e-02, -4.4198420e-02, -1.8555950e-02],\n",
              "        [ 7.7015534e-03,  1.4470223e-02,  2.0395145e-03],\n",
              "        [ 4.9058344e-02,  2.1654677e-02, -8.7254122e-04],\n",
              "        [-3.8616288e-02, -8.9075677e-03, -4.4052314e-02]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCUFwsJPgujN"
      },
      "source": [
        "# WordNet\n",
        "\n",
        "-Thesaurus\n",
        "\n",
        "단어의 유사도를 거리로 표현 \n",
        "\n",
        "$ similarity(w,w') = - log distance(w,w')$  \n",
        "  \n",
        "  \n",
        "### Local Representation\n",
        "\n",
        "- 해당 단어 그 자체만 보고 특정값을 맵핑하여 단어를 표현\n",
        "### distributed Representation\n",
        "- 그 단어를 표현하고자 주변을 참고하여 단어를 표현\n",
        "\n",
        "#### beg of words\n",
        "- 단어들의 순서는 전혀 고려하지 않고, 단어들의 출현 빈도(frequency)에만 집중하는 텍스트 데이터의 수치화 표현 방법\n",
        ">만드는 과정\n",
        ">> 1. 각 단어에 고유한 정수 인덱스를 부여한다.\n",
        ">> 1. 각 인덱스의 위치에 단어 토큰의 등장 횟수를 기록한 벡터를 만든다\n",
        "\n",
        "##### 문서 단어 행렬 (Document_Term Matrix, DTM)\n",
        "- 각 문서에서 등장한 단어의 빈도를 행렬의 값으로 표기\n",
        "- 문서 단어 행렬은 문서들을 서로 비교할 수 있도록 수치화 할 수 있다는 점에 의의!\n",
        "- 단점\n",
        "> 희소 표현  \n",
        ">> 각 문서 벡터의 차원은 원-핫 벡터와 마찬가지로 전체 단어 집합의 크기를 가짐 \n",
        ">> 많은 문서벡터가 대부분의 0의 값을 가질 수 있음\n",
        ">> 희소 벡터는 많은 양의 저장공간과 계산을 위한 리소스가 필요  \n",
        "\n",
        "  > 단순 빈도 수 기반 접근\n",
        "\n",
        "##### TF-IDF\n",
        "1. 텍스트 마이닝(Text Mining)에서 중요하게 사용\n",
        "1. 어떤 단어 w가 문서 d 내에서 얼마나 중요한지 나타내는 수치\n",
        "1. TF(Tern Frequency)\n",
        "  - 단어의 문서 내에 출현한 횟수\n",
        "  - 숫자가 클수록 문서 내에서 중요한 단어\n",
        "  - 하지만 'the'와 같은 단어도 `TF`값이 매우 클 것\n",
        "\n",
        "##### IDF(Inverse Document Frequency)\n",
        "- 그 단어가 출현한 문서의 역수(Inverse)\n",
        "- 값이 클 수록 'the'와 가이 일반적으로 많이 쓰이는 단어\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzfV8oA0ldGg"
      },
      "source": [
        "# Beg of words\n",
        "- 단어의 등장 순서를 고려하지 않은 빈도수 기반의 단어 표현 방법\n",
        "  1. 각 단어의 고유한 정수 인덱스를 부여\n",
        "  1. 각 인덱스 위치에 단어 토큰의 등장 횟수를 기록한 벡터를 만든다. \n",
        "\n",
        "``` python\n",
        "doc1= 'Jone likes to watch movies. Mary likes movies too'\n",
        "Bow1 = { \"Jone\" : 1, \"likes\" : 2 , \"watch\" : 1, \"movies\": 2, \"Mary\" : 1, \"too: :1}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMzcCW9HgUt_",
        "outputId": "b5160e2b-6296-44d9-8e95-057ebafa91b7"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 7.1 MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 42.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.10.8)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTCljvudli3Z"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "import re\n",
        "\n",
        "okt = Okt()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLAn_HC6qLpU",
        "outputId": "3310f869-bbff-4b42-f4e3-cc86e08376df"
      },
      "source": [
        "# 정규표현식을 통해 온점을 제거하는 정제 작업\n",
        "token = re.sub(\"(\\.)\",\"\",\"소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.\")\n",
        "\n",
        "token = okt.morphs(token)\n",
        "token"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['소비자', '는', '주로', '소비', '하는', '상품', '을', '기준', '으로', '물가상승률', '을', '느낀다']"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnptRiwGqbMj",
        "outputId": "0f1fd986-d95f-492a-e124-88247a424899"
      },
      "source": [
        "word2index = {}\n",
        "bow = []\n",
        "\n",
        "for voca in token:\n",
        "  if voca not in word2index.keys():\n",
        "    word2index[voca] = len(word2index) # token 을 읽으면서 , 없는 단어를 새로 추가, \n",
        "    bow.insert(len(word2index)-1, 1) # 기본값 1을 넣어둔다.\n",
        "  else:\n",
        "    index = word2index.get(voca) # 재등장 단어 \n",
        "    bow[index] = bow[index] + 1\n",
        "\n",
        "print(word2index)\n",
        "print(bow)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'소비자': 0, '는': 1, '주로': 2, '소비': 3, '하는': 4, '상품': 5, '을': 6, '기준': 7, '으로': 8, '물가상승률': 9, '느낀다': 10}\n",
            "[1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnoV7ku7ra7P"
      },
      "source": [
        "### Tensorflow keras tokenizer를 사용해서 bow구하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUJ4Ztamq7ZS"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "sentence = [\n",
        "            'Jone likes to watch movies. \\\n",
        "            Mary likes movies too! \\\n",
        "            Mary also likes to watch football games.']"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1mjIpYIr5li"
      },
      "source": [
        "def print_bow(sentence):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(sentence) # 단어장 생성\n",
        "  bow = dict(tokenizer.word_counts) #bow 저장\n",
        "  print('Bag of words : ', bow)\n",
        "  print('단어장(Vocabulary)의 크기 : ',len(tokenizer.word_counts))\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2VF2gf2sJ8m",
        "outputId": "e9057cbd-b78b-4cb7-9364-7af3d0fdc708"
      },
      "source": [
        "print_bow(sentence)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag of words :  {'jone': 1, 'likes': 3, 'to': 2, 'watch': 2, 'movies': 2, 'mary': 2, 'too': 1, 'also': 1, 'football': 1, 'games': 1}\n",
            "단어장(Vocabulary)의 크기 :  10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enlLMRLwsdSO"
      },
      "source": [
        "### sklearn의 CountVectorizer을 활용한 bow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVUz-z9TsUEZ",
        "outputId": "dd5ef452-5985-457c-e1e9-7b065831111d"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "sentence = ['Jone likes to watch movies. \\\n",
        "            Mary likes movies too! \\\n",
        "            Mary also likes to watch football games.']\n",
        "\n",
        "vector = CountVectorizer()\n",
        "print(\"Bag of Words : \",vector.fit_transform(sentence).toarray()) \n",
        "print(\"각 단어의 인덱스 : \", vector.vocabulary_)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag of Words :  [[1 1 1 1 3 2 2 2 1 2]]\n",
            "각 단어의 인덱스 :  {'jone': 3, 'likes': 4, 'to': 7, 'watch': 9, 'movies': 6, 'mary': 5, 'too': 8, 'also': 0, 'football': 1, 'games': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiCDNj5QtSO4"
      },
      "source": [
        "### 사용자가 직접 정의한 불용어(The an ...)를 제거한 bow 만들기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRmrIe5Xs1t9",
        "outputId": "5968a89e-c2ac-466b-a5ef-b61e312c116d"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "text = [\"Family is not an important thing. It's everything\"]\n",
        "\n",
        "vect = CountVectorizer(stop_words = ['the','a','an','is','not'])  # stop_words에 list형식으로 불용어 지정\n",
        "\n",
        "print(vect.fit_transform(text).toarray())\n",
        "print(vect.vocabulary_)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 1 1]]\n",
            "{'family': 1, 'important': 2, 'thing': 4, 'it': 3, 'everything': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zix8ADGyunX9"
      },
      "source": [
        "### CountVectorizer에서 제공하는 자체 불용어를 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh0e3hFluKc1",
        "outputId": "0ff8c84f-4fb0-454a-c3b0-256fc8cfde4e"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "text = [\"Family is not an important thing. It's everything\"]\n",
        "\n",
        "vect = CountVectorizer(stop_words = 'english')  #  countervectorizer에서 제공하는 불용어를 제거 (영어 english)\n",
        "\n",
        "print(vect.fit_transform(text).toarray())\n",
        "print(vect.vocabulary_)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1]]\n",
            "{'family': 0, 'important': 1, 'thing': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UISD6X7vFiP"
      },
      "source": [
        "### NLTK에서 지원하는 불용어 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9SpSWTRuwym",
        "outputId": "44854e6a-bd91-469e-c14c-73e9ecddf06d"
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuTnVS43vPCr",
        "outputId": "80b7d838-6736-4ffc-f6e1-c3468d014e29"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "text = [\"Family is not an important thing. It's everything\"]\n",
        "\n",
        "sw = stopwords.words('english')\n",
        "vect = CountVectorizer(stop_words = sw)  #  countervectorizer에서 제공하는 불용어를 제거 (영어 english)\n",
        "\n",
        "print(vect.fit_transform(text).toarray())\n",
        "print(vect.vocabulary_)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 1]]\n",
            "{'family': 1, 'important': 2, 'thing': 3, 'everything': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28E_fT9OxlkV"
      },
      "source": [
        "# DTM(Document Term Metrix)\n",
        "\n",
        "- 다수의 문서에서 등장하는 각 단어들의 빈도를 행렬로 표현한 것\n",
        "- 다수의 문서에 대해서 Bow를 하나의 행렬로 표현하고 부르는 용어\n",
        "--------------------------------------\n",
        "\n",
        "문서 1 : I like dog  \n",
        "문서 2 : I like cat  \n",
        "문서 3 : I like cat I like cat  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "0LvNc2CHvfaX",
        "outputId": "8ab66057-6c2a-4ec4-bb62-2187325a2c7e"
      },
      "source": [
        "import pandas as pd\n",
        "content = [[0, 1, 1, 1], [1, 0, 1, 1], [2, 0, 2, 2,]]\n",
        "df = pd.DataFrame(content)\n",
        "df.index = ['(문서1) I like dog', '(문서2) I like cat', '(문서3) I like cat I like cat']\n",
        "df.columns = ['cat', 'dog', 'I', 'like']\n",
        "df"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cat</th>\n",
              "      <th>dog</th>\n",
              "      <th>I</th>\n",
              "      <th>like</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>(문서1) I like dog</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(문서2) I like cat</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(문서3) I like cat I like cat</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             cat  dog  I  like\n",
              "(문서1) I like dog               0    1  1     1\n",
              "(문서2) I like cat               1    0  1     1\n",
              "(문서3) I like cat I like cat    2    0  2     2"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocPuqbrNyESi"
      },
      "source": [
        "import numpy as np\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "doc1 = np.array([0,1,1,1])\n",
        "doc2 = np.array([1,0,1,1])\n",
        "doc3 = np.array([2,0,2,2])\n",
        "\n",
        "#  get cos similarlity \n",
        "def cos_sim(a,b):  # 코사인 유사도는 0~1사이의 값을 가지고, 1에 가까울 수록 유사도가 높다고 판단\n",
        "  return dot(a,b)/(norm(a) * norm(b))"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfkQYkGGyiij",
        "outputId": "b65741d3-feeb-4fd6-df2d-0ce49664c90e"
      },
      "source": [
        "print(cos_sim(doc1,doc2))\n",
        "print(cos_sim(doc1,doc3))\n",
        "print(cos_sim(doc2,doc3))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6666666666666667\n",
            "0.6666666666666667\n",
            "1.0000000000000002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVshuVbgzGA_"
      },
      "source": [
        "### sklearn CountVectorizer를 활용한 DTM 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_Vu2DhGypcM",
        "outputId": "147374e0-d3ff-4c32-e779-8c16bb75ddac"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "corpus = ['Jone likes to watch movies. \\\n",
        "            Mary likes movies too! \\\n",
        "            Mary also likes to watch football games.']\n",
        "\n",
        "vector = CountVectorizer()\n",
        "print(vector.fit_transform(corpus).toarray())\n",
        "print(vector.vocabulary_)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 1 3 2 2 2 1 2]]\n",
            "{'jone': 3, 'likes': 4, 'to': 7, 'watch': 9, 'movies': 6, 'mary': 5, 'too': 8, 'also': 0, 'football': 1, 'games': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq5_CacVztd3"
      },
      "source": [
        "#### TF-IDF(Term-Frequency-Inverse Document Frequency)\n",
        "- 모든 문서에서 자주 등장하는 단어는 중요도가 낮다고 판단\n",
        "- 특정 문서에서만 자주 등장하는 단어는 중요도가 높고 판단\n",
        "\n",
        "$ TF-IDF(w,d) = \\frac{TF(w,d)}{DF(w)}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaiFRRZ5zXyQ"
      },
      "source": [
        "from math import log\n",
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "docs = [\n",
        "        'John likes to watch movies and Mary likes movies too',\n",
        "        'James likes to watch TV',\n",
        "        'Mary also likes to watch football games',\n",
        "]"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NdciG870lse",
        "outputId": "071addd5-a4ac-4a5e-e107-f5a429e6152d"
      },
      "source": [
        "vocab = list(set(w for doc in docs for w in doc.split()))\n",
        "vocab.sort()\n",
        "\n",
        "print('단어장의 크기 :', len(vocab))\n",
        "print(vocab)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어장의 크기 : 13\n",
            "['James', 'John', 'Mary', 'TV', 'also', 'and', 'football', 'games', 'likes', 'movies', 'to', 'too', 'watch']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nXXHblW0mdY"
      },
      "source": [
        "N =len(docs)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svqiap4v1af5"
      },
      "source": [
        "$ idf(d,t) = log\\frac{N}{1+df(t)} $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvDTlW8N0ow9"
      },
      "source": [
        "def tf(t,d): # 특정 문서 d에서의 특정 단어 t의 등장 횟수\n",
        "  return d.count(t)\n",
        "\n",
        "def idf(t): # 반비례 하는 수\n",
        "  df = 0 # 특정 단어 t가 등장한 문서의 수\n",
        "  for doc in docs:\n",
        "    df += t in doc\n",
        "  return log(N/(df+1)) + 1\n",
        "\n",
        "def tfidf(t,d):\n",
        "  return tf(t,d) * idf(t)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "rfEPa-Ns08az",
        "outputId": "d129e7c6-7816-493d-b00a-f2909e96a6e0"
      },
      "source": [
        "result = []\n",
        "\n",
        "for i in range(N):\n",
        "  result.append([])\n",
        "  d = docs[i]\n",
        "  for j in range(len(vocab)):\n",
        "    t = vocab[j]\n",
        "\n",
        "    result[-1].append(tf(t,d))\n",
        "\n",
        "tf_ = pd.DataFrame(result, columns = vocab)\n",
        "tf_.head()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>James</th>\n",
              "      <th>John</th>\n",
              "      <th>Mary</th>\n",
              "      <th>TV</th>\n",
              "      <th>also</th>\n",
              "      <th>and</th>\n",
              "      <th>football</th>\n",
              "      <th>games</th>\n",
              "      <th>likes</th>\n",
              "      <th>movies</th>\n",
              "      <th>to</th>\n",
              "      <th>too</th>\n",
              "      <th>watch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   James  John  Mary  TV  also  and  ...  games  likes  movies  to  too  watch\n",
              "0      0     1     1   0     0    1  ...      0      2       2   2    1      1\n",
              "1      1     0     0   1     0    0  ...      0      1       0   1    0      1\n",
              "2      0     0     1   0     1    0  ...      1      1       0   1    0      1\n",
              "\n",
              "[3 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "hAj3uLOh1N55",
        "outputId": "f63cf499-e628-4e32-b6f2-52934a54e03d"
      },
      "source": [
        "result = [] \n",
        "for j in range(len(vocab)):\n",
        "  t = vocab[j]\n",
        "  result.append(idf(t))\n",
        "\n",
        "idf_ = pd.DataFrame(result,index = vocab, columns=['idf'])\n",
        "idf_"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>James</th>\n",
              "      <td>1.405465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>John</th>\n",
              "      <td>1.405465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mary</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TV</th>\n",
              "      <td>1.405465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>also</th>\n",
              "      <td>1.405465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>and</th>\n",
              "      <td>1.405465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>football</th>\n",
              "      <td>1.405465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>games</th>\n",
              "      <td>1.405465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>likes</th>\n",
              "      <td>0.712318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>movies</th>\n",
              "      <td>1.405465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>to</th>\n",
              "      <td>0.712318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>too</th>\n",
              "      <td>1.405465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>watch</th>\n",
              "      <td>0.712318</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               idf\n",
              "James     1.405465\n",
              "John      1.405465\n",
              "Mary      1.000000\n",
              "TV        1.405465\n",
              "also      1.405465\n",
              "and       1.405465\n",
              "football  1.405465\n",
              "games     1.405465\n",
              "likes     0.712318\n",
              "movies    1.405465\n",
              "to        0.712318\n",
              "too       1.405465\n",
              "watch     0.712318"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "YjheRp6C1518",
        "outputId": "a880083b-f5bc-445e-ce63-453225ef1587"
      },
      "source": [
        "result = []\n",
        "for i in range(N):\n",
        "    result.append([])\n",
        "    d = docs[i]\n",
        "    for j in range(len(vocab)):\n",
        "        t = vocab[j]\n",
        "\n",
        "        result[-1].append(tfidf(t,d))\n",
        "tfidf_=pd.DataFrame(result, columns=vocab)\n",
        "tfidf_"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>James</th>\n",
              "      <th>John</th>\n",
              "      <th>Mary</th>\n",
              "      <th>TV</th>\n",
              "      <th>also</th>\n",
              "      <th>and</th>\n",
              "      <th>football</th>\n",
              "      <th>games</th>\n",
              "      <th>likes</th>\n",
              "      <th>movies</th>\n",
              "      <th>to</th>\n",
              "      <th>too</th>\n",
              "      <th>watch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.405465</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.405465</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.424636</td>\n",
              "      <td>2.81093</td>\n",
              "      <td>1.424636</td>\n",
              "      <td>1.405465</td>\n",
              "      <td>0.712318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.405465</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.405465</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.712318</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.712318</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.712318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.405465</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.405465</td>\n",
              "      <td>1.405465</td>\n",
              "      <td>0.712318</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.712318</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.712318</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      James      John  Mary        TV  ...   movies        to       too     watch\n",
              "0  0.000000  1.405465   1.0  0.000000  ...  2.81093  1.424636  1.405465  0.712318\n",
              "1  1.405465  0.000000   0.0  1.405465  ...  0.00000  0.712318  0.000000  0.712318\n",
              "2  0.000000  0.000000   1.0  0.000000  ...  0.00000  0.712318  0.000000  0.712318\n",
              "\n",
              "[3 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ngnl6-d-2rhl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}